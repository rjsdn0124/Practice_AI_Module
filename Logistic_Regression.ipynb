{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOB/p7OTyRSUSAlxFVXk/EP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rjsdn0124/Practice_AI_Module/blob/main/Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 파이토치로 다중 로지스틱 회귀 구현하기"
      ],
      "metadata": {
        "id": "U8ZhhWVvU1t-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3p7E0r7sbq-P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fa5b530-a33f-40e5-b42e-06ff2b4cb302"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 2])\n",
            "torch.Size([6, 1])\n",
            "tensor([[0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000],\n",
            "        [0.5000]], grad_fn=<SigmoidBackward0>)\n",
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "==============================\n",
            "Epoch    0/1000 Cost: 0.693147\n",
            "Epoch  100/1000 Cost: 0.134722\n",
            "Epoch  200/1000 Cost: 0.080643\n",
            "Epoch  300/1000 Cost: 0.057900\n",
            "Epoch  400/1000 Cost: 0.045300\n",
            "Epoch  500/1000 Cost: 0.037261\n",
            "Epoch  600/1000 Cost: 0.031673\n",
            "Epoch  700/1000 Cost: 0.027556\n",
            "Epoch  800/1000 Cost: 0.024394\n",
            "Epoch  900/1000 Cost: 0.021888\n",
            "Epoch 1000/1000 Cost: 0.019852\n",
            "tensor([[2.7711e-04],\n",
            "        [3.1636e-02],\n",
            "        [3.9014e-02],\n",
            "        [9.5618e-01],\n",
            "        [9.9823e-01],\n",
            "        [9.9969e-01]], grad_fn=<SigmoidBackward0>)\n",
            "tensor([[False],\n",
            "        [False],\n",
            "        [False],\n",
            "        [ True],\n",
            "        [ True],\n",
            "        [ True]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "# 0.5가 넘으면 True르 반환시키고자 함.\n",
        "\n",
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "# X가 현재 [6,2] 형태이므로 [6,1]로 만들어주기 위해 WX형태로 만들어 주려면 W는 [2,1]이 되어야 해서 해당 형태로 설정.\n",
        "W = torch.zeros((2,1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "# W와 b는 현재 0으로 초기화된 상태. 이 상태에서 여러 과정을 통해 오차를 구해서 손실함수로 계산 후 기울기 재 설정 후 W,b 재설정.\n",
        "\n",
        "# hypothesis = 1 / (1 + torch.exp(-(x_train.matmul(W) + b))) \n",
        "# 위의 식을 torch에선 sigmoid 함수로 사용.\n",
        "hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n",
        "print(hypothesis)\n",
        "print(y_train)\n",
        "\n",
        "# losses = -(y_train * torch.log(hypothesis) + (1 - y_train) * torch.log(1 - hypothesis))\n",
        "# cost = losses.mean()\n",
        "# 해당 식도 함수로 구현되어있음\n",
        "cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "\n",
        "# 훈련 과정>>\n",
        "optimizer = optim.SGD([W, b], lr=1)\n",
        "\n",
        "print('='*30)\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # Cost 계산\n",
        "    hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n",
        "    cost = -(y_train * torch.log(hypothesis) + \n",
        "             (1 - y_train) * torch.log(1 - hypothesis)).mean()\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))\n",
        "        \n",
        "print(hypothesis)\n",
        "prediction = hypothesis >= torch.FloatTensor([0.5])\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## nn.Module을 통해 구현하기\n"
      ],
      "metadata": {
        "id": "peTT9IkFU0nE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(2,1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "# forward시킬 모듈 생성.\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "nb_epochs = 2000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산 forward\n",
        "    hypothesis = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.binary_cross_entropy(hypothesis, y_train) # 모델의 매개변수를 통해 해당 H(x)계산한 값이랑 오차를 계산해서 저장.\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad() # 모델의 매개변수의 변화도를 재설정하기위해 0으로 초기화. 변화도는 계속 더해지는 코드라 0으로 계속 초기화 필요.\n",
        "    cost.backward() # 모델의 매개변수의 변화도를 계산하여 재설정해야하는 변화량 계산.\n",
        "    optimizer.step() # backward를 통해 model의 매개변수 객체에서 변화량이 변경된거를 확인하여 변경시켜주는 함수. 여기서 실질적 변경 일어남.\n",
        "\n",
        "    # 20번마다 로그 출력\n",
        "    if epoch % 10 == 0:\n",
        "        prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True로 간주\n",
        "        correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\n",
        "        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format( # 각 에포크마다 정확도를 출력\n",
        "            epoch, nb_epochs, cost.item(), accuracy * 100,\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZZXEHDeYqzB",
        "outputId": "d90f2469-eee1-4a52-cb7e-6e108215509b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 0.539713 Accuracy 83.33%\n",
            "Epoch   10/2000 Cost: 0.614853 Accuracy 66.67%\n",
            "Epoch   20/2000 Cost: 0.441875 Accuracy 66.67%\n",
            "Epoch   30/2000 Cost: 0.373145 Accuracy 83.33%\n",
            "Epoch   40/2000 Cost: 0.316358 Accuracy 83.33%\n",
            "Epoch   50/2000 Cost: 0.266094 Accuracy 83.33%\n",
            "Epoch   60/2000 Cost: 0.220498 Accuracy 100.00%\n",
            "Epoch   70/2000 Cost: 0.182095 Accuracy 100.00%\n",
            "Epoch   80/2000 Cost: 0.157299 Accuracy 100.00%\n",
            "Epoch   90/2000 Cost: 0.144091 Accuracy 100.00%\n",
            "Epoch  100/2000 Cost: 0.134272 Accuracy 100.00%\n",
            "Epoch  110/2000 Cost: 0.125769 Accuracy 100.00%\n",
            "Epoch  120/2000 Cost: 0.118297 Accuracy 100.00%\n",
            "Epoch  130/2000 Cost: 0.111680 Accuracy 100.00%\n",
            "Epoch  140/2000 Cost: 0.105779 Accuracy 100.00%\n",
            "Epoch  150/2000 Cost: 0.100483 Accuracy 100.00%\n",
            "Epoch  160/2000 Cost: 0.095704 Accuracy 100.00%\n",
            "Epoch  170/2000 Cost: 0.091369 Accuracy 100.00%\n",
            "Epoch  180/2000 Cost: 0.087420 Accuracy 100.00%\n",
            "Epoch  190/2000 Cost: 0.083806 Accuracy 100.00%\n",
            "Epoch  200/2000 Cost: 0.080486 Accuracy 100.00%\n",
            "Epoch  210/2000 Cost: 0.077425 Accuracy 100.00%\n",
            "Epoch  220/2000 Cost: 0.074595 Accuracy 100.00%\n",
            "Epoch  230/2000 Cost: 0.071969 Accuracy 100.00%\n",
            "Epoch  240/2000 Cost: 0.069526 Accuracy 100.00%\n",
            "Epoch  250/2000 Cost: 0.067248 Accuracy 100.00%\n",
            "Epoch  260/2000 Cost: 0.065118 Accuracy 100.00%\n",
            "Epoch  270/2000 Cost: 0.063122 Accuracy 100.00%\n",
            "Epoch  280/2000 Cost: 0.061247 Accuracy 100.00%\n",
            "Epoch  290/2000 Cost: 0.059483 Accuracy 100.00%\n",
            "Epoch  300/2000 Cost: 0.057820 Accuracy 100.00%\n",
            "Epoch  310/2000 Cost: 0.056250 Accuracy 100.00%\n",
            "Epoch  320/2000 Cost: 0.054764 Accuracy 100.00%\n",
            "Epoch  330/2000 Cost: 0.053357 Accuracy 100.00%\n",
            "Epoch  340/2000 Cost: 0.052022 Accuracy 100.00%\n",
            "Epoch  350/2000 Cost: 0.050753 Accuracy 100.00%\n",
            "Epoch  360/2000 Cost: 0.049546 Accuracy 100.00%\n",
            "Epoch  370/2000 Cost: 0.048396 Accuracy 100.00%\n",
            "Epoch  380/2000 Cost: 0.047299 Accuracy 100.00%\n",
            "Epoch  390/2000 Cost: 0.046252 Accuracy 100.00%\n",
            "Epoch  400/2000 Cost: 0.045251 Accuracy 100.00%\n",
            "Epoch  410/2000 Cost: 0.044294 Accuracy 100.00%\n",
            "Epoch  420/2000 Cost: 0.043376 Accuracy 100.00%\n",
            "Epoch  430/2000 Cost: 0.042497 Accuracy 100.00%\n",
            "Epoch  440/2000 Cost: 0.041653 Accuracy 100.00%\n",
            "Epoch  450/2000 Cost: 0.040843 Accuracy 100.00%\n",
            "Epoch  460/2000 Cost: 0.040064 Accuracy 100.00%\n",
            "Epoch  470/2000 Cost: 0.039315 Accuracy 100.00%\n",
            "Epoch  480/2000 Cost: 0.038593 Accuracy 100.00%\n",
            "Epoch  490/2000 Cost: 0.037898 Accuracy 100.00%\n",
            "Epoch  500/2000 Cost: 0.037228 Accuracy 100.00%\n",
            "Epoch  510/2000 Cost: 0.036582 Accuracy 100.00%\n",
            "Epoch  520/2000 Cost: 0.035958 Accuracy 100.00%\n",
            "Epoch  530/2000 Cost: 0.035356 Accuracy 100.00%\n",
            "Epoch  540/2000 Cost: 0.034773 Accuracy 100.00%\n",
            "Epoch  550/2000 Cost: 0.034210 Accuracy 100.00%\n",
            "Epoch  560/2000 Cost: 0.033664 Accuracy 100.00%\n",
            "Epoch  570/2000 Cost: 0.033137 Accuracy 100.00%\n",
            "Epoch  580/2000 Cost: 0.032625 Accuracy 100.00%\n",
            "Epoch  590/2000 Cost: 0.032130 Accuracy 100.00%\n",
            "Epoch  600/2000 Cost: 0.031649 Accuracy 100.00%\n",
            "Epoch  610/2000 Cost: 0.031183 Accuracy 100.00%\n",
            "Epoch  620/2000 Cost: 0.030730 Accuracy 100.00%\n",
            "Epoch  630/2000 Cost: 0.030291 Accuracy 100.00%\n",
            "Epoch  640/2000 Cost: 0.029864 Accuracy 100.00%\n",
            "Epoch  650/2000 Cost: 0.029449 Accuracy 100.00%\n",
            "Epoch  660/2000 Cost: 0.029046 Accuracy 100.00%\n",
            "Epoch  670/2000 Cost: 0.028654 Accuracy 100.00%\n",
            "Epoch  680/2000 Cost: 0.028272 Accuracy 100.00%\n",
            "Epoch  690/2000 Cost: 0.027900 Accuracy 100.00%\n",
            "Epoch  700/2000 Cost: 0.027538 Accuracy 100.00%\n",
            "Epoch  710/2000 Cost: 0.027186 Accuracy 100.00%\n",
            "Epoch  720/2000 Cost: 0.026842 Accuracy 100.00%\n",
            "Epoch  730/2000 Cost: 0.026507 Accuracy 100.00%\n",
            "Epoch  740/2000 Cost: 0.026181 Accuracy 100.00%\n",
            "Epoch  750/2000 Cost: 0.025862 Accuracy 100.00%\n",
            "Epoch  760/2000 Cost: 0.025552 Accuracy 100.00%\n",
            "Epoch  770/2000 Cost: 0.025248 Accuracy 100.00%\n",
            "Epoch  780/2000 Cost: 0.024952 Accuracy 100.00%\n",
            "Epoch  790/2000 Cost: 0.024663 Accuracy 100.00%\n",
            "Epoch  800/2000 Cost: 0.024381 Accuracy 100.00%\n",
            "Epoch  810/2000 Cost: 0.024104 Accuracy 100.00%\n",
            "Epoch  820/2000 Cost: 0.023835 Accuracy 100.00%\n",
            "Epoch  830/2000 Cost: 0.023571 Accuracy 100.00%\n",
            "Epoch  840/2000 Cost: 0.023313 Accuracy 100.00%\n",
            "Epoch  850/2000 Cost: 0.023061 Accuracy 100.00%\n",
            "Epoch  860/2000 Cost: 0.022814 Accuracy 100.00%\n",
            "Epoch  870/2000 Cost: 0.022572 Accuracy 100.00%\n",
            "Epoch  880/2000 Cost: 0.022336 Accuracy 100.00%\n",
            "Epoch  890/2000 Cost: 0.022104 Accuracy 100.00%\n",
            "Epoch  900/2000 Cost: 0.021877 Accuracy 100.00%\n",
            "Epoch  910/2000 Cost: 0.021655 Accuracy 100.00%\n",
            "Epoch  920/2000 Cost: 0.021437 Accuracy 100.00%\n",
            "Epoch  930/2000 Cost: 0.021224 Accuracy 100.00%\n",
            "Epoch  940/2000 Cost: 0.021015 Accuracy 100.00%\n",
            "Epoch  950/2000 Cost: 0.020810 Accuracy 100.00%\n",
            "Epoch  960/2000 Cost: 0.020609 Accuracy 100.00%\n",
            "Epoch  970/2000 Cost: 0.020412 Accuracy 100.00%\n",
            "Epoch  980/2000 Cost: 0.020219 Accuracy 100.00%\n",
            "Epoch  990/2000 Cost: 0.020029 Accuracy 100.00%\n",
            "Epoch 1000/2000 Cost: 0.019843 Accuracy 100.00%\n",
            "Epoch 1010/2000 Cost: 0.019660 Accuracy 100.00%\n",
            "Epoch 1020/2000 Cost: 0.019481 Accuracy 100.00%\n",
            "Epoch 1030/2000 Cost: 0.019305 Accuracy 100.00%\n",
            "Epoch 1040/2000 Cost: 0.019132 Accuracy 100.00%\n",
            "Epoch 1050/2000 Cost: 0.018962 Accuracy 100.00%\n",
            "Epoch 1060/2000 Cost: 0.018796 Accuracy 100.00%\n",
            "Epoch 1070/2000 Cost: 0.018632 Accuracy 100.00%\n",
            "Epoch 1080/2000 Cost: 0.018471 Accuracy 100.00%\n",
            "Epoch 1090/2000 Cost: 0.018312 Accuracy 100.00%\n",
            "Epoch 1100/2000 Cost: 0.018157 Accuracy 100.00%\n",
            "Epoch 1110/2000 Cost: 0.018004 Accuracy 100.00%\n",
            "Epoch 1120/2000 Cost: 0.017854 Accuracy 100.00%\n",
            "Epoch 1130/2000 Cost: 0.017706 Accuracy 100.00%\n",
            "Epoch 1140/2000 Cost: 0.017560 Accuracy 100.00%\n",
            "Epoch 1150/2000 Cost: 0.017417 Accuracy 100.00%\n",
            "Epoch 1160/2000 Cost: 0.017277 Accuracy 100.00%\n",
            "Epoch 1170/2000 Cost: 0.017138 Accuracy 100.00%\n",
            "Epoch 1180/2000 Cost: 0.017002 Accuracy 100.00%\n",
            "Epoch 1190/2000 Cost: 0.016868 Accuracy 100.00%\n",
            "Epoch 1200/2000 Cost: 0.016736 Accuracy 100.00%\n",
            "Epoch 1210/2000 Cost: 0.016606 Accuracy 100.00%\n",
            "Epoch 1220/2000 Cost: 0.016478 Accuracy 100.00%\n",
            "Epoch 1230/2000 Cost: 0.016353 Accuracy 100.00%\n",
            "Epoch 1240/2000 Cost: 0.016228 Accuracy 100.00%\n",
            "Epoch 1250/2000 Cost: 0.016106 Accuracy 100.00%\n",
            "Epoch 1260/2000 Cost: 0.015986 Accuracy 100.00%\n",
            "Epoch 1270/2000 Cost: 0.015868 Accuracy 100.00%\n",
            "Epoch 1280/2000 Cost: 0.015751 Accuracy 100.00%\n",
            "Epoch 1290/2000 Cost: 0.015636 Accuracy 100.00%\n",
            "Epoch 1300/2000 Cost: 0.015523 Accuracy 100.00%\n",
            "Epoch 1310/2000 Cost: 0.015411 Accuracy 100.00%\n",
            "Epoch 1320/2000 Cost: 0.015301 Accuracy 100.00%\n",
            "Epoch 1330/2000 Cost: 0.015192 Accuracy 100.00%\n",
            "Epoch 1340/2000 Cost: 0.015085 Accuracy 100.00%\n",
            "Epoch 1350/2000 Cost: 0.014980 Accuracy 100.00%\n",
            "Epoch 1360/2000 Cost: 0.014876 Accuracy 100.00%\n",
            "Epoch 1370/2000 Cost: 0.014773 Accuracy 100.00%\n",
            "Epoch 1380/2000 Cost: 0.014672 Accuracy 100.00%\n",
            "Epoch 1390/2000 Cost: 0.014572 Accuracy 100.00%\n",
            "Epoch 1400/2000 Cost: 0.014474 Accuracy 100.00%\n",
            "Epoch 1410/2000 Cost: 0.014377 Accuracy 100.00%\n",
            "Epoch 1420/2000 Cost: 0.014281 Accuracy 100.00%\n",
            "Epoch 1430/2000 Cost: 0.014186 Accuracy 100.00%\n",
            "Epoch 1440/2000 Cost: 0.014093 Accuracy 100.00%\n",
            "Epoch 1450/2000 Cost: 0.014001 Accuracy 100.00%\n",
            "Epoch 1460/2000 Cost: 0.013910 Accuracy 100.00%\n",
            "Epoch 1470/2000 Cost: 0.013820 Accuracy 100.00%\n",
            "Epoch 1480/2000 Cost: 0.013732 Accuracy 100.00%\n",
            "Epoch 1490/2000 Cost: 0.013644 Accuracy 100.00%\n",
            "Epoch 1500/2000 Cost: 0.013558 Accuracy 100.00%\n",
            "Epoch 1510/2000 Cost: 0.013473 Accuracy 100.00%\n",
            "Epoch 1520/2000 Cost: 0.013389 Accuracy 100.00%\n",
            "Epoch 1530/2000 Cost: 0.013306 Accuracy 100.00%\n",
            "Epoch 1540/2000 Cost: 0.013224 Accuracy 100.00%\n",
            "Epoch 1550/2000 Cost: 0.013142 Accuracy 100.00%\n",
            "Epoch 1560/2000 Cost: 0.013062 Accuracy 100.00%\n",
            "Epoch 1570/2000 Cost: 0.012983 Accuracy 100.00%\n",
            "Epoch 1580/2000 Cost: 0.012905 Accuracy 100.00%\n",
            "Epoch 1590/2000 Cost: 0.012828 Accuracy 100.00%\n",
            "Epoch 1600/2000 Cost: 0.012752 Accuracy 100.00%\n",
            "Epoch 1610/2000 Cost: 0.012676 Accuracy 100.00%\n",
            "Epoch 1620/2000 Cost: 0.012602 Accuracy 100.00%\n",
            "Epoch 1630/2000 Cost: 0.012528 Accuracy 100.00%\n",
            "Epoch 1640/2000 Cost: 0.012455 Accuracy 100.00%\n",
            "Epoch 1650/2000 Cost: 0.012384 Accuracy 100.00%\n",
            "Epoch 1660/2000 Cost: 0.012312 Accuracy 100.00%\n",
            "Epoch 1670/2000 Cost: 0.012242 Accuracy 100.00%\n",
            "Epoch 1680/2000 Cost: 0.012173 Accuracy 100.00%\n",
            "Epoch 1690/2000 Cost: 0.012104 Accuracy 100.00%\n",
            "Epoch 1700/2000 Cost: 0.012036 Accuracy 100.00%\n",
            "Epoch 1710/2000 Cost: 0.011969 Accuracy 100.00%\n",
            "Epoch 1720/2000 Cost: 0.011903 Accuracy 100.00%\n",
            "Epoch 1730/2000 Cost: 0.011837 Accuracy 100.00%\n",
            "Epoch 1740/2000 Cost: 0.011772 Accuracy 100.00%\n",
            "Epoch 1750/2000 Cost: 0.011708 Accuracy 100.00%\n",
            "Epoch 1760/2000 Cost: 0.011644 Accuracy 100.00%\n",
            "Epoch 1770/2000 Cost: 0.011581 Accuracy 100.00%\n",
            "Epoch 1780/2000 Cost: 0.011519 Accuracy 100.00%\n",
            "Epoch 1790/2000 Cost: 0.011458 Accuracy 100.00%\n",
            "Epoch 1800/2000 Cost: 0.011397 Accuracy 100.00%\n",
            "Epoch 1810/2000 Cost: 0.011337 Accuracy 100.00%\n",
            "Epoch 1820/2000 Cost: 0.011277 Accuracy 100.00%\n",
            "Epoch 1830/2000 Cost: 0.011218 Accuracy 100.00%\n",
            "Epoch 1840/2000 Cost: 0.011160 Accuracy 100.00%\n",
            "Epoch 1850/2000 Cost: 0.011102 Accuracy 100.00%\n",
            "Epoch 1860/2000 Cost: 0.011045 Accuracy 100.00%\n",
            "Epoch 1870/2000 Cost: 0.010988 Accuracy 100.00%\n",
            "Epoch 1880/2000 Cost: 0.010932 Accuracy 100.00%\n",
            "Epoch 1890/2000 Cost: 0.010877 Accuracy 100.00%\n",
            "Epoch 1900/2000 Cost: 0.010822 Accuracy 100.00%\n",
            "Epoch 1910/2000 Cost: 0.010768 Accuracy 100.00%\n",
            "Epoch 1920/2000 Cost: 0.010714 Accuracy 100.00%\n",
            "Epoch 1930/2000 Cost: 0.010661 Accuracy 100.00%\n",
            "Epoch 1940/2000 Cost: 0.010608 Accuracy 100.00%\n",
            "Epoch 1950/2000 Cost: 0.010556 Accuracy 100.00%\n",
            "Epoch 1960/2000 Cost: 0.010504 Accuracy 100.00%\n",
            "Epoch 1970/2000 Cost: 0.010453 Accuracy 100.00%\n",
            "Epoch 1980/2000 Cost: 0.010403 Accuracy 100.00%\n",
            "Epoch 1990/2000 Cost: 0.010352 Accuracy 100.00%\n",
            "Epoch 2000/2000 Cost: 0.010303 Accuracy 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##. by Model\n"
      ],
      "metadata": {
        "id": "nXoPLw2TnB3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_data = [[0], [0], [0], [1], [1], [1]]\n",
        "x_train = torch.FloatTensor(x_data)\n",
        "y_train = torch.FloatTensor(y_data)\n",
        "\n",
        "class BinaryClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(2,1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.sigmoid(self.linear(x))\n",
        "\n",
        "model = BinaryClassifier()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr = 1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    hypothesis = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 20번마다 로그 출력\n",
        "    if epoch % 10 == 0:\n",
        "        prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True로 간주\n",
        "        correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\n",
        "        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format( # 각 에포크마다 정확도를 출력\n",
        "            epoch, nb_epochs, cost.item(), accuracy * 100,\n",
        "        ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0c6_ZkFgWT-",
        "outputId": "b3249d84-1b62-46db-9deb-026529690568"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 Cost: 0.614994 Accuracy 66.67%\n",
            "Epoch   10/1000 Cost: 0.747550 Accuracy 83.33%\n",
            "Epoch   20/1000 Cost: 0.633216 Accuracy 83.33%\n",
            "Epoch   30/1000 Cost: 0.538123 Accuracy 83.33%\n",
            "Epoch   40/1000 Cost: 0.450406 Accuracy 83.33%\n",
            "Epoch   50/1000 Cost: 0.366382 Accuracy 83.33%\n",
            "Epoch   60/1000 Cost: 0.287368 Accuracy 83.33%\n",
            "Epoch   70/1000 Cost: 0.219289 Accuracy 83.33%\n",
            "Epoch   80/1000 Cost: 0.173225 Accuracy 100.00%\n",
            "Epoch   90/1000 Cost: 0.151674 Accuracy 100.00%\n",
            "Epoch  100/1000 Cost: 0.140280 Accuracy 100.00%\n",
            "Epoch  110/1000 Cost: 0.131002 Accuracy 100.00%\n",
            "Epoch  120/1000 Cost: 0.122903 Accuracy 100.00%\n",
            "Epoch  130/1000 Cost: 0.115765 Accuracy 100.00%\n",
            "Epoch  140/1000 Cost: 0.109426 Accuracy 100.00%\n",
            "Epoch  150/1000 Cost: 0.103760 Accuracy 100.00%\n",
            "Epoch  160/1000 Cost: 0.098664 Accuracy 100.00%\n",
            "Epoch  170/1000 Cost: 0.094056 Accuracy 100.00%\n",
            "Epoch  180/1000 Cost: 0.089870 Accuracy 100.00%\n",
            "Epoch  190/1000 Cost: 0.086050 Accuracy 100.00%\n",
            "Epoch  200/1000 Cost: 0.082549 Accuracy 100.00%\n",
            "Epoch  210/1000 Cost: 0.079328 Accuracy 100.00%\n",
            "Epoch  220/1000 Cost: 0.076356 Accuracy 100.00%\n",
            "Epoch  230/1000 Cost: 0.073604 Accuracy 100.00%\n",
            "Epoch  240/1000 Cost: 0.071048 Accuracy 100.00%\n",
            "Epoch  250/1000 Cost: 0.068668 Accuracy 100.00%\n",
            "Epoch  260/1000 Cost: 0.066446 Accuracy 100.00%\n",
            "Epoch  270/1000 Cost: 0.064367 Accuracy 100.00%\n",
            "Epoch  280/1000 Cost: 0.062417 Accuracy 100.00%\n",
            "Epoch  290/1000 Cost: 0.060584 Accuracy 100.00%\n",
            "Epoch  300/1000 Cost: 0.058858 Accuracy 100.00%\n",
            "Epoch  310/1000 Cost: 0.057231 Accuracy 100.00%\n",
            "Epoch  320/1000 Cost: 0.055692 Accuracy 100.00%\n",
            "Epoch  330/1000 Cost: 0.054236 Accuracy 100.00%\n",
            "Epoch  340/1000 Cost: 0.052856 Accuracy 100.00%\n",
            "Epoch  350/1000 Cost: 0.051546 Accuracy 100.00%\n",
            "Epoch  360/1000 Cost: 0.050301 Accuracy 100.00%\n",
            "Epoch  370/1000 Cost: 0.049115 Accuracy 100.00%\n",
            "Epoch  380/1000 Cost: 0.047986 Accuracy 100.00%\n",
            "Epoch  390/1000 Cost: 0.046908 Accuracy 100.00%\n",
            "Epoch  400/1000 Cost: 0.045878 Accuracy 100.00%\n",
            "Epoch  410/1000 Cost: 0.044893 Accuracy 100.00%\n",
            "Epoch  420/1000 Cost: 0.043951 Accuracy 100.00%\n",
            "Epoch  430/1000 Cost: 0.043048 Accuracy 100.00%\n",
            "Epoch  440/1000 Cost: 0.042182 Accuracy 100.00%\n",
            "Epoch  450/1000 Cost: 0.041351 Accuracy 100.00%\n",
            "Epoch  460/1000 Cost: 0.040552 Accuracy 100.00%\n",
            "Epoch  470/1000 Cost: 0.039784 Accuracy 100.00%\n",
            "Epoch  480/1000 Cost: 0.039045 Accuracy 100.00%\n",
            "Epoch  490/1000 Cost: 0.038334 Accuracy 100.00%\n",
            "Epoch  500/1000 Cost: 0.037649 Accuracy 100.00%\n",
            "Epoch  510/1000 Cost: 0.036987 Accuracy 100.00%\n",
            "Epoch  520/1000 Cost: 0.036349 Accuracy 100.00%\n",
            "Epoch  530/1000 Cost: 0.035734 Accuracy 100.00%\n",
            "Epoch  540/1000 Cost: 0.035138 Accuracy 100.00%\n",
            "Epoch  550/1000 Cost: 0.034563 Accuracy 100.00%\n",
            "Epoch  560/1000 Cost: 0.034006 Accuracy 100.00%\n",
            "Epoch  570/1000 Cost: 0.033468 Accuracy 100.00%\n",
            "Epoch  580/1000 Cost: 0.032946 Accuracy 100.00%\n",
            "Epoch  590/1000 Cost: 0.032441 Accuracy 100.00%\n",
            "Epoch  600/1000 Cost: 0.031951 Accuracy 100.00%\n",
            "Epoch  610/1000 Cost: 0.031476 Accuracy 100.00%\n",
            "Epoch  620/1000 Cost: 0.031014 Accuracy 100.00%\n",
            "Epoch  630/1000 Cost: 0.030567 Accuracy 100.00%\n",
            "Epoch  640/1000 Cost: 0.030132 Accuracy 100.00%\n",
            "Epoch  650/1000 Cost: 0.029710 Accuracy 100.00%\n",
            "Epoch  660/1000 Cost: 0.029299 Accuracy 100.00%\n",
            "Epoch  670/1000 Cost: 0.028900 Accuracy 100.00%\n",
            "Epoch  680/1000 Cost: 0.028512 Accuracy 100.00%\n",
            "Epoch  690/1000 Cost: 0.028134 Accuracy 100.00%\n",
            "Epoch  700/1000 Cost: 0.027766 Accuracy 100.00%\n",
            "Epoch  710/1000 Cost: 0.027407 Accuracy 100.00%\n",
            "Epoch  720/1000 Cost: 0.027058 Accuracy 100.00%\n",
            "Epoch  730/1000 Cost: 0.026718 Accuracy 100.00%\n",
            "Epoch  740/1000 Cost: 0.026386 Accuracy 100.00%\n",
            "Epoch  750/1000 Cost: 0.026063 Accuracy 100.00%\n",
            "Epoch  760/1000 Cost: 0.025747 Accuracy 100.00%\n",
            "Epoch  770/1000 Cost: 0.025439 Accuracy 100.00%\n",
            "Epoch  780/1000 Cost: 0.025138 Accuracy 100.00%\n",
            "Epoch  790/1000 Cost: 0.024845 Accuracy 100.00%\n",
            "Epoch  800/1000 Cost: 0.024558 Accuracy 100.00%\n",
            "Epoch  810/1000 Cost: 0.024278 Accuracy 100.00%\n",
            "Epoch  820/1000 Cost: 0.024004 Accuracy 100.00%\n",
            "Epoch  830/1000 Cost: 0.023737 Accuracy 100.00%\n",
            "Epoch  840/1000 Cost: 0.023475 Accuracy 100.00%\n",
            "Epoch  850/1000 Cost: 0.023219 Accuracy 100.00%\n",
            "Epoch  860/1000 Cost: 0.022969 Accuracy 100.00%\n",
            "Epoch  870/1000 Cost: 0.022724 Accuracy 100.00%\n",
            "Epoch  880/1000 Cost: 0.022484 Accuracy 100.00%\n",
            "Epoch  890/1000 Cost: 0.022250 Accuracy 100.00%\n",
            "Epoch  900/1000 Cost: 0.022020 Accuracy 100.00%\n",
            "Epoch  910/1000 Cost: 0.021795 Accuracy 100.00%\n",
            "Epoch  920/1000 Cost: 0.021574 Accuracy 100.00%\n",
            "Epoch  930/1000 Cost: 0.021358 Accuracy 100.00%\n",
            "Epoch  940/1000 Cost: 0.021147 Accuracy 100.00%\n",
            "Epoch  950/1000 Cost: 0.020939 Accuracy 100.00%\n",
            "Epoch  960/1000 Cost: 0.020736 Accuracy 100.00%\n",
            "Epoch  970/1000 Cost: 0.020536 Accuracy 100.00%\n",
            "Epoch  980/1000 Cost: 0.020340 Accuracy 100.00%\n",
            "Epoch  990/1000 Cost: 0.020148 Accuracy 100.00%\n",
            "Epoch 1000/1000 Cost: 0.019960 Accuracy 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_ZFjD7bwgUv0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}